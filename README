# -*- coding: utf-8 -*-
Алгоритм
1 забрать страницу
2 при докачке ресурсов страницы, отфильтровать рекламные и мусорные ресурсы
3 убрать не существенные ветки дерева ресурсов html
4 преобразовать ссылки, заголовки, абзацы, другие теги
5 ограничить ширину строки и сохранить текст в  файл

рекламу и мусорные теги решено удалять при помощи правил adblock
Для создания этих правил есть удобные расширения да и сами правила отлично формализованы.


Зависимости
веб браузер(выбор обусловлен тем что данная реализация браузера позволяет при необходимости поддерживать jquery и AJAX что обычно критично для паука
плюс опыт работы со spynner у меня имелся)
sudo easy_install spynner

Упрощенный парсер для работы с контентом
sudo pip install pyparsing
Быстрый врапер длинных строк
 textwrap

парсер адблок правил
взят с https://github.com/atereshkin/abpy 
и откорректирован
сами правила взяты с
wget https://easylist-downloads.adblockplus.org/ruadlist+easylist.txt
типовой шаблон для статьи создается с помощью adblock в браузере
и копируется в текстовый файл

 

ТЕСТ
python main.py -f lenta.txt http://lenta.ru/news/2015/07/07/senator_speaks/
результаты предствалены в соответсвующем файле
lenta.ru/news/2015/07/07/senator_speaks/index.txt

Идеи по развитию 
- по хорошему блокировку(сокрытие) элементов(тегов) html следует делать через реализацию своего парсера(наследуясь от HTMLParser.HTMLParser) и прописав его в spynner.browser( через set_html_parser)
но я не пошел по этому пути считая что реализация качественного парсера потребует значительных временных затрат
- убирать ссылки из отображения без читаемого текста
- расширить поддержку adblock rules
- проверка валидности URL
- Поддержка запросов POST и поддержка авторизации 
- асинхронные запросы в сеть (уберет проблему с лагами)
- поиск на странице версии для печати
- поддержка прокси


